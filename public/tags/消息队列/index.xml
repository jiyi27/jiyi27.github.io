<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>消息队列 on 为霜的博客</title>
    <link>https://blog.jiyi27.com/tags/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/</link>
    <description>Recent content in 消息队列 on 为霜的博客</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Sun, 16 Mar 2025 11:45:27 +0000</lastBuildDate><atom:link href="https://blog.jiyi27.com/tags/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Kafka vs RabbitMQ</title>
      <link>https://blog.jiyi27.com/posts/interview/%E7%BC%93%E5%AD%98%E5%92%8C%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/001-kafka-rabbitmq/</link>
      <pubDate>Sun, 16 Mar 2025 11:45:27 +0000</pubDate>
      
      <guid>https://blog.jiyi27.com/posts/interview/%E7%BC%93%E5%AD%98%E5%92%8C%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/001-kafka-rabbitmq/</guid>
      <description>&lt;h2 id=&#34;1-rabbitmq&#34;&gt;1. RabbitMQ&lt;/h2&gt;
&lt;h3 id=&#34;11-优缺点&#34;&gt;1.1. 优缺点&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;协议与消息模型灵活&lt;/strong&gt; RabbitMQ 基于 AMQP，可以实现多种路由策略（Direct、Fanout、Topic、Headers 等），在工作队列、发布订阅、RPC 等模式下都有成熟支持, 对编程语言、协议的兼容性好（STOMP、MQTT、AMQP 等）&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;低延迟&lt;/strong&gt; 对于单条消息的快速投递、即时消费，RabbitMQ 的延迟通常可以控制在微秒到毫秒级，特别适合传统应用内的即时通信或实时响应业务&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;吞吐量较难达到 Kafka 的级别&lt;/strong&gt; RabbitMQ 也支持集群，但对于大规模数据流场景，其扩展性和稳定性往往不及 Kafka（轻量级队列系统与大数据流平台设计初衷不同）&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;消息持久化开销&lt;/strong&gt; 若需要实现高可用持久化（开启镜像队列、确认机制、磁盘持久化等），在吞吐量和存储成本上会有一定牺牲&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;生态对于实时计算弱&lt;/strong&gt; 相比 Kafka 自带或社区中完善的数据处理组件，RabbitMQ 主要聚焦在消息路由和队列本身，对大数据实时处理场景支持有限&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;AMQP Advanced Message Queuing Protocol, 是一种开放标准的应用层协议, AMQP 的核心目标是实现跨平台、跨语言的互操作性, AMQP 的主要组件包括：&lt;/p&gt;
&lt;p&gt;交换机（Exchange）：负责接收生产者发送的消息，并根据路由规则将消息分发到合适的队列&lt;/p&gt;
&lt;p&gt;队列（Queue）：存储消息的地方，消费者从队列中获取消息&lt;/p&gt;
&lt;p&gt;绑定（Binding）：交换机和队列之间的关联，定义了消息的路由规则&lt;/p&gt;
&lt;p&gt;路由键（Routing Key）：用于匹配消息和队列的标识&lt;/p&gt;
&lt;p&gt;它支持多种工作模式, 简单模式, 工作队列模式, 发布/订阅模式, 路由模式等&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;12-使用场景&#34;&gt;1.2. 使用场景&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;传统应用中的异步处理&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;比如 Web 后端业务系统，需要&lt;strong&gt;快速返回请求&lt;/strong&gt;，将后续的处理放到消息队列里异步执行&lt;/li&gt;
&lt;li&gt;场景：下单后异步扣库存、发送通知邮件、短信等&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;实时通信或低延迟请求&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;需要消息在亚毫秒到毫秒级延迟内到达消费者进行处理&lt;/li&gt;
&lt;li&gt;场景：实时消息推送、微服务 RPC、在线聊天系统等&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;多种路由策略&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;RabbitMQ 丰富的交换机（Exchange）类型可以满足&lt;strong&gt;复杂业务路由&lt;/strong&gt;需求：如按不同 RoutingKey 分发给不同队列&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;2-kafka&#34;&gt;2. Kafka&lt;/h2&gt;
&lt;h3 id=&#34;21-优缺点&#34;&gt;2.1. 优缺点&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;高吞吐量和可扩展性&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;核心功能是面向高吞吐量、可扩展性以及持久化的日志系统&lt;/li&gt;
&lt;li&gt;Kafka 通过 Partition 进行横向扩展，可支持海量消息的高并发写入与读取&lt;/li&gt;
&lt;li&gt;整体架构设计适合大规模分布式部署&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;持久化与顺序读取&lt;/strong&gt;&lt;/p&gt;</description>
      <content>&lt;h2 id=&#34;1-rabbitmq&#34;&gt;1. RabbitMQ&lt;/h2&gt;
&lt;h3 id=&#34;11-优缺点&#34;&gt;1.1. 优缺点&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;协议与消息模型灵活&lt;/strong&gt; RabbitMQ 基于 AMQP，可以实现多种路由策略（Direct、Fanout、Topic、Headers 等），在工作队列、发布订阅、RPC 等模式下都有成熟支持, 对编程语言、协议的兼容性好（STOMP、MQTT、AMQP 等）&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;低延迟&lt;/strong&gt; 对于单条消息的快速投递、即时消费，RabbitMQ 的延迟通常可以控制在微秒到毫秒级，特别适合传统应用内的即时通信或实时响应业务&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;吞吐量较难达到 Kafka 的级别&lt;/strong&gt; RabbitMQ 也支持集群，但对于大规模数据流场景，其扩展性和稳定性往往不及 Kafka（轻量级队列系统与大数据流平台设计初衷不同）&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;消息持久化开销&lt;/strong&gt; 若需要实现高可用持久化（开启镜像队列、确认机制、磁盘持久化等），在吞吐量和存储成本上会有一定牺牲&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;生态对于实时计算弱&lt;/strong&gt; 相比 Kafka 自带或社区中完善的数据处理组件，RabbitMQ 主要聚焦在消息路由和队列本身，对大数据实时处理场景支持有限&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;AMQP Advanced Message Queuing Protocol, 是一种开放标准的应用层协议, AMQP 的核心目标是实现跨平台、跨语言的互操作性, AMQP 的主要组件包括：&lt;/p&gt;
&lt;p&gt;交换机（Exchange）：负责接收生产者发送的消息，并根据路由规则将消息分发到合适的队列&lt;/p&gt;
&lt;p&gt;队列（Queue）：存储消息的地方，消费者从队列中获取消息&lt;/p&gt;
&lt;p&gt;绑定（Binding）：交换机和队列之间的关联，定义了消息的路由规则&lt;/p&gt;
&lt;p&gt;路由键（Routing Key）：用于匹配消息和队列的标识&lt;/p&gt;
&lt;p&gt;它支持多种工作模式, 简单模式, 工作队列模式, 发布/订阅模式, 路由模式等&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;12-使用场景&#34;&gt;1.2. 使用场景&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;传统应用中的异步处理&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;比如 Web 后端业务系统，需要&lt;strong&gt;快速返回请求&lt;/strong&gt;，将后续的处理放到消息队列里异步执行&lt;/li&gt;
&lt;li&gt;场景：下单后异步扣库存、发送通知邮件、短信等&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;实时通信或低延迟请求&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;需要消息在亚毫秒到毫秒级延迟内到达消费者进行处理&lt;/li&gt;
&lt;li&gt;场景：实时消息推送、微服务 RPC、在线聊天系统等&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;多种路由策略&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;RabbitMQ 丰富的交换机（Exchange）类型可以满足&lt;strong&gt;复杂业务路由&lt;/strong&gt;需求：如按不同 RoutingKey 分发给不同队列&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;2-kafka&#34;&gt;2. Kafka&lt;/h2&gt;
&lt;h3 id=&#34;21-优缺点&#34;&gt;2.1. 优缺点&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;高吞吐量和可扩展性&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;核心功能是面向高吞吐量、可扩展性以及持久化的日志系统&lt;/li&gt;
&lt;li&gt;Kafka 通过 Partition 进行横向扩展，可支持海量消息的高并发写入与读取&lt;/li&gt;
&lt;li&gt;整体架构设计适合大规模分布式部署&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;持久化与顺序读取&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Kafka 中所有消息被持久化到磁盘，默认设置下也会进行副本（Replication）存储，故障恢复快、可靠性强&lt;/li&gt;
&lt;li&gt;消费端通过 offset（偏移量）来定位消息&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;完善的生态&lt;/strong&gt; Kafka Streams、ksqlDB、Connect 等组件支持实时计算、数据管道构建，便于与大数据体系对接（例如 Spark、Flink 等）&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;消息投递不是严格的实时&lt;/strong&gt; Kafka 侧重批量、流式吞吐量，延迟（Latency）相对于某些传统消息队列来说会稍高, 通常在毫秒到秒级，适合高吞吐场景&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;消息模型相对简单&lt;/strong&gt; Kafka 更强调分区、顺序的日志模型，在交换机/路由等维度的功能相比 RabbitMQ 等 AMQP 消息队列要简单一些&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;相对复杂的运维与管理&lt;/strong&gt; 集群依赖 ZooKeeper，对运维人员有一定要求&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;为什么 RabbitMQ 低延迟, 吞吐量却没 Kafka 高?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;吞吐量可以简单理解为每秒可以稳定处理 10 万条消息, 这就是高吞吐量, 延迟是指一条消息从 Producer 发送, 到 Consumer 收到并确认, 花了 5ms, 这就是“延迟”, 延迟更低意味着对单条消息来说, 响应更快, 低延迟通常意味着对每条消息采取“及时处理”的方式, 减少批量, 高吞吐量往往依赖批量发送、批量压缩、以及并行处理等技术手段&lt;/p&gt;
&lt;p&gt;RabbitMQ 可能对&lt;strong&gt;单个消息进行直接的推送&lt;/strong&gt;模式，没什么额外开销，特别是如果是内存队列或者轻量持久化，所以其单条消息可在很短时间内被消费&lt;/p&gt;
&lt;p&gt;Kafka 在架构上着重于&lt;strong&gt;分区扩展&lt;/strong&gt;、顺序写磁盘、&lt;strong&gt;批量 I/O&lt;/strong&gt;，并且往往部署在多 Broker 的&lt;strong&gt;分布式集群&lt;/strong&gt;上，能轻松承载数万至数十万甚至更高 TPS 的数据写入和消费, 对单条消息而言，可能有毫秒到秒级的等待时间，但在单位时间内可以处理非常庞大的消息总量（高吞吐量）&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&#34;22-使用场景&#34;&gt;2.2. 使用场景&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;大数据、日志收集&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;大量日志、事件实时进入 Kafka，再对接下游 Spark、Flink、Hadoop 等进行数据分析、存储或流式处理&lt;/li&gt;
&lt;li&gt;场景：电商订单流水、用户行为日志收集等&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;实时流处理与监控&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;配合 Kafka Streams、ksqlDB 或第三方流处理框架做实时数据分析、监控报警&lt;/li&gt;
&lt;li&gt;场景：金融实时风控、监控数据聚合等&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;事件驱动架构&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;微服务之间通过 Kafka 进行解耦，可实现高吞吐的异步通信与事件广播&lt;/li&gt;
&lt;li&gt;场景：大型互联网应用中，后端微服务之间的异步处理&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;3-总结&#34;&gt;3. 总结&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;高吞吐量 + 大规模数据流 + 实时/离线分析场景 → Kafka&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;如果系统需要&lt;strong&gt;承受海量数据&lt;/strong&gt;的写入与消费（几十万甚至几百万级别的 TPS），并且需要对接大数据生态做后续处理，那么 Kafka 更合适&lt;/li&gt;
&lt;li&gt;Kafka 提供 Partition 级别的横向扩展和日志存储模型，对历史消息也能回溯&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;轻量级任务队列 + 多种路由策略 + 低延迟场景 → RabbitMQ&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;如果你需要&lt;strong&gt;传统消息队列&lt;/strong&gt;（AMQP）模型，以及在微服务中实现更灵活的&lt;strong&gt;路由&lt;/strong&gt;或&lt;strong&gt;通信&lt;/strong&gt;，RabbitMQ 的实现成本更低、生态成熟&lt;/li&gt;
&lt;li&gt;适合相对&lt;strong&gt;中等规模&lt;/strong&gt;的消息量，对延迟敏感性较高的系统&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;内部服务间的简单解耦&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;小规模场景下，RabbitMQ 足以胜任；大规模或预期未来数据量剧增，则可考虑一次性上 Kafka 以免后期大量迁移&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;从业务需求层面考虑：&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;是否需要回放消息？&lt;/strong&gt; 如果经常需要回放/重放，Kafka 的分区存储和 offset 机制十分方便&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;是否需要强大的流处理生态？&lt;/strong&gt; 如果需要针对实时数据做流计算和分析，Kafka 生态支持更完善&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;是否需要复杂路由规则？&lt;/strong&gt; RabbitMQ 的交换机模型在复杂路由上可能更具灵活性&lt;/li&gt;
&lt;/ul&gt;
</content>
    </item>
    
    <item>
      <title>Kafka 消息队列</title>
      <link>https://blog.jiyi27.com/posts/interview/%E7%BC%93%E5%AD%98%E5%92%8C%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/001-kafka-concepts/</link>
      <pubDate>Sat, 22 Feb 2025 16:10:27 +0000</pubDate>
      
      <guid>https://blog.jiyi27.com/posts/interview/%E7%BC%93%E5%AD%98%E5%92%8C%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/001-kafka-concepts/</guid>
      <description>&lt;h2 id=&#34;1-几个重要概念&#34;&gt;1. 几个重要概念&lt;/h2&gt;
&lt;p&gt;Kafka 几个常见概念: Producer, Consumer, Broker, Topic, Partition:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;在 Kafka 中, 集群里的每一台服务器都被称为 &lt;strong&gt;Broker&lt;/strong&gt;, 负责接收生产者发送的消息并存储这些消息&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Topic 是 Kafka 中消息的逻辑分组, 生产者按照消息所属 Topic 将消息发送到 Broker, 消费者从  Broker 中读取消息&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;每个 Topic 可以分成多个分区, 然后不同的分区可能会存储在不同的 Broker 上, 例如: &lt;code&gt;user-clicks&lt;/code&gt; Topic 有 3 个分区, 可能分布在 2 个 Broker 上，Broker 1 存分区 0 和 1，Broker 2 存分区 2&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;注意 Broker 本身并不主动“分发”消息, 只负责存储消息并等待消费者主动拉取&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;分区（Partition）&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;每个 Topic 被分成多个分区，分区是 Kafka 数据的基本存储单位&lt;/li&gt;
&lt;li&gt;例如，一个 Topic user-clicks 有 3 个分区：Partition 0、Partition 1、Partition 2&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;副本（Replica）&lt;/p&gt;</description>
      <content>&lt;h2 id=&#34;1-几个重要概念&#34;&gt;1. 几个重要概念&lt;/h2&gt;
&lt;p&gt;Kafka 几个常见概念: Producer, Consumer, Broker, Topic, Partition:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;在 Kafka 中, 集群里的每一台服务器都被称为 &lt;strong&gt;Broker&lt;/strong&gt;, 负责接收生产者发送的消息并存储这些消息&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Topic 是 Kafka 中消息的逻辑分组, 生产者按照消息所属 Topic 将消息发送到 Broker, 消费者从  Broker 中读取消息&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;每个 Topic 可以分成多个分区, 然后不同的分区可能会存储在不同的 Broker 上, 例如: &lt;code&gt;user-clicks&lt;/code&gt; Topic 有 3 个分区, 可能分布在 2 个 Broker 上，Broker 1 存分区 0 和 1，Broker 2 存分区 2&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;注意 Broker 本身并不主动“分发”消息, 只负责存储消息并等待消费者主动拉取&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;分区（Partition）&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;每个 Topic 被分成多个分区，分区是 Kafka 数据的基本存储单位&lt;/li&gt;
&lt;li&gt;例如，一个 Topic user-clicks 有 3 个分区：Partition 0、Partition 1、Partition 2&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;副本（Replica）&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;每个分区可以有多个副本（由复制因子 replication-factor 决定），这些副本分布在不同的 Broker 上&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;例如，replication-factor=2 表示每个分区有 2 个副本：一个主副本（Leader Replica）和一个从副本（Follower Replica）&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;在 Kafka 集群里，不是一台 Broker 扛所有活，而是多台 Broker 一起上。数据先按照 Topic 分类，每个 Topic 又被拆分成多个分区，这些分区会均匀分布到不同的 Broker 上。这样，生产者在写入数据、消费者在读取数据时，相关请求会自动分散到各个 Broker，从而实现负载均衡和高吞吐量&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;2-异步处理&#34;&gt;2. 异步处理&lt;/h2&gt;
&lt;p&gt;异步处理是指任务的发起和执行不要求实时同步完成, 消息队列常用于异步处理, 生产者将消息发送到队列后无需等待消费者立即处理, 可以继续执行其他任务, 从而提高系统效率,&lt;/p&gt;
&lt;p&gt;之前讨论高并发点赞的问题, 用到了 Redis Lua 脚本保证了 &lt;code&gt;检查+更新&lt;/code&gt; 面临的数据一致性问题, 然后利用 Kafka 实现了异步更新到数据库, 这也算是消息队列异步处理常见的一个应用场景,&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;异步处理优点是解耦服务、提高响应速度和容错性；缺点可能是数据一致性难以保证（比如消费者处理失败），需要额外的错误处理机制（如重试或死信队列）&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;3-消息持久化&#34;&gt;3. 消息持久化&lt;/h2&gt;
&lt;p&gt;我觉得至少有几个问题需要先弄明白, 我们知道消息由生产者产生发送到 Broker, 然后 Broker 存储消息, 之后的事由 消费者主动消费(拉取)消息,&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;消息默认存在哪个位置的?&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;为什么需要消息持久化呢, 消息不就是为了消费的吗, 如果存在磁盘保存起来, 消费者频繁读取, 读取之后的消息应该视为无用的垃圾了吧, 难道还要分别删除, 这也太浪费性能了吧?&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;31-消息默认存在哪个位置的&#34;&gt;3.1. 消息默认存在哪个位置的?&lt;/h3&gt;
&lt;p&gt;在 Kafka 中, 消息是按 Topic 归类的, 可以理解为一类消息放在同一个 Topic 中:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;每个 Topic 的每个分区对应一个日志文件（例如 topic-name-0.log）&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;如果一个 Topic 只有 1 个分区，那么所有消息都会顺序追加到这个分区上&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;如果一个 Topic 有多个分区，那么生产者会根据一定的策略（Key 的哈希或者轮询等）把消息分散到不同的分区&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;在 Kafka 的 Broker 上, 每个分区的底层都对应着一个日志文件, 这个日志并不是单独的一个物理文件，而是一系列 Segment 文件的有序集合, 形成一个“日志”概念:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;你可以把它理解成一个“顺序追加写”的结构, 每当生产者发送的消息抵达该分区时, Kafka 就将它顺序地追加到 Log 的尾部（对应 Segment 文件）&lt;/li&gt;
&lt;li&gt;为了方便维护和查询，Kafka 会把一个分区的 Log 拆分为多个 Segment 进行管理&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;32-为什么是磁盘而不是内存&#34;&gt;3.2. 为什么是磁盘而不是内存？&lt;/h3&gt;
&lt;p&gt;简单一句话为了保证可靠性, 消息队列和 Redis 缓存还不一样, 缓存的数据丢失可以在业务逻辑上通过双写一致性保证, 毕竟缓存的数据就是为了提高速度, 权威数据 Source of Truth 还是在数据库里的, 而消息队列不同, 消息丢了就是丢了, 因为它本身就是权威数据,&lt;/p&gt;
&lt;p&gt;在消息被消费者消费之前, 如果 Broker 宕机, 内存中的消息会丢失, 而磁盘上的消息可以恢复,&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Kafka 的设计目标是高吞吐量和高可靠性，直接把消息存在内存中虽然快，但内存容量有限，且宕机后数据会丢失&lt;/li&gt;
&lt;li&gt;Kafka 通过顺序写入磁盘（而不是随机读写）和操作系统的页面缓存（Page Cache），让磁盘的性能接近内存的读写速度&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;现代磁盘（无论是机械硬盘还是 SSD）在处理顺序写入时, 性能表现通常远优于随机写入:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;当数据是顺序写入的时候, 磁盘连续地写入数据, 不需要频繁地更换写入位置, 避免了磁头寻道（或者在SSD中内部块寻址）的开销, 从而极大地提高了写入速度, 而随机写入要求磁盘在不同位置之间不断切换, 造成额外的延时和性能下降,&lt;/li&gt;
&lt;li&gt;Kafka 采用的是&lt;strong&gt;追加写入&lt;/strong&gt;的方式, 也就是每次都是在日志文件的末尾顺序写入数据, 从而避免了随机访问的开销&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;p&gt;看完上面的不仅好奇 Kafka 还能控制操作系统的页面缓存吗? 这是怎么实现的?&lt;/p&gt;
&lt;h4 id=&#34;321-什么是页面缓存-page-cache&#34;&gt;3.2.1. 什么是页面缓存 (Page Cache)&lt;/h4&gt;
&lt;p&gt;页面缓存是操作系统在内存中开辟出的一块区域, 用来临时存储从磁盘读取的数据, 或者即将写入磁盘的数据, 其主要作用有：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;读缓存: 当应用再次请求已经被缓存的数据时，可以直接从内存中获取数据，大大提高读取速度&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;写缓存: 数据写入时，操作系统可以先将数据写入页面缓存，然后异步地将数据刷新（flush）到磁盘，这样应用看起来是直接在内存中写入数据&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;322-kafka-怎么利用页面缓存&#34;&gt;3.2.2. Kafka 怎么利用页面缓存&lt;/h4&gt;
&lt;p&gt;Kafka 是一个分布式消息系统，它需要处理大量的消息读写。为了做到高吞吐量和高可靠性，Kafka 选择把消息持久化到磁盘上，而不是只保存在内存中。但磁盘很慢，怎么才能让性能接近内存呢？答案就是巧妙利用操作系统的页面缓存。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;顺序写入磁盘&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Kafka 写入数据时，不是随机跳来跳去地写（随机写很慢），而是按顺序追加到日志文件末尾&lt;/li&gt;
&lt;li&gt;顺序写入非常快，因为磁盘读写时不需要频繁移动磁头（对于机械硬盘）或者做复杂寻址（对于 SSD）&lt;/li&gt;
&lt;li&gt;写完之后，这些数据会被操作系统自动加载到页面缓存中&lt;/li&gt;
&lt;li&gt;顺序追加写入可以利用操作系统对顺序数据写入的优化, 这让操作系统更容易把数据缓存到页面缓存中&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;操作系统在管理页面缓存时, 更倾向于&lt;strong&gt;缓存连续的数据块&lt;/strong&gt;, 顺序写入的数据通常会被预先加载到页面缓存中, 因为操作系统认为接下来很可能还会访问相邻的数据, 这样可以避免频繁地进行磁盘读写, 直接从内存中读取数据, 速度更快&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;依赖页面缓存加速读取&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;当消费者（Consumer）来读取消息时，Kafka 不会直接去磁盘找数据，而是让操作系统从页面缓存里拿&lt;/li&gt;
&lt;li&gt;因为刚写入的数据还在页面缓存中（内存里），读取速度几乎和直接从内存读一样快&lt;/li&gt;
&lt;li&gt;如果数据不在缓存中，操作系统会从磁盘加载到页面缓存，然后再给 Kafka，这样后续的读取也能变快&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;尽量少干预缓存管理&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Kafka 并不自己管理内存, 而是把缓存的工作交给操作系统, 操作系统的页面缓存机制已经很成熟, 能根据系统的内存使用情况自动调整哪些数据保留在缓存里, 哪些可以丢弃&lt;/p&gt;
&lt;h3 id=&#34;33-消息被消费后-会被立马删除吗&#34;&gt;3.3. 消息被消费后 会被立马删除吗&lt;/h3&gt;
&lt;p&gt;Kafka 不会在每条消息写完后就跑去删除，而是 “以 Segment 为单位” 进行清理：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;当 Segment 中所有消息都超过了保留时间（或者日志大小达到限制）时, 这个 Segment 文件就可以被删除&lt;/li&gt;
&lt;li&gt;Kafka 会周期性地检查每个分区日志中最早的 Segment 是否已经满足删除条件, 如果满足, 就把这个 Segment 文件（以及对应的 &lt;code&gt;.index&lt;/code&gt;、&lt;code&gt;.timeindex&lt;/code&gt; 文件）从磁盘上删除&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Consumer 读取消息的时候，只需要记录自己当前消费到哪个 offset 并提交, 即使这条消息还在 Kafka 的日志文件里, 它是否被删除是由上面提到的保留策略决定, 并不因为 Consumer 读到它就删除&lt;/p&gt;
&lt;h3 id=&#34;34-为什么不浪费性能&#34;&gt;3.4. 为什么不浪费性能&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;**顺序写Append-only + 批量处理 Batch **：消费者不是一条条读，而是批量拉取消息（比如一次拉 1000 条），减少频繁交互, 最大化磁盘吞吐，减少网络请求、磁盘刷盘次数，提升写入与读取性能&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;零拷贝技术&lt;/strong&gt;：Kafka 使用操作系统的零拷贝（Zero Copy）机制，从磁盘到网络传输消息时不经过用户态，效率极高&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;操作系统 Page Cache&lt;/strong&gt;：通过操作系统缓存机制来提升文件的读写效率，减少实际磁盘 IO；配合零拷贝进一步提升传输性能&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;自动清理&lt;/strong&gt;：消息过期后，Kafka 后台线程自动删除老日志，不需要人工干预，也不需要消费者操心&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;什么是零拷贝（Zero Copy）？&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;通常情况下，当程序（比如 Kafka 的 Broker）需要把数据从磁盘发送到网络（比如给消费者），会涉及多次数据拷贝：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;操作系统从磁盘读取数据，拷贝到内核态的缓冲区（Kernel Buffer）&lt;/li&gt;
&lt;li&gt;从内核态缓冲区拷贝到用户态的应用程序内存（比如 Kafka 的进程内存）&lt;/li&gt;
&lt;li&gt;应用程序处理完后，再把数据从用户态内存拷贝回内核态的网络缓冲区&lt;/li&gt;
&lt;li&gt;最后从内核态网络缓冲区发送到网卡，传给消费者&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;这个过程涉及多次数据拷贝（通常至少 4 次），而且在用户态和内核态之间切换（上下文切换），会消耗 CPU 和时间，效率不高, &lt;strong&gt;零拷贝&lt;/strong&gt;的目标是：尽量减少这些拷贝步骤，尤其是用户态和内核态之间的来回拷贝。操作系统提供了一些技术（比如 &lt;code&gt;sendfile&lt;/code&gt; 系统调用），让数据直接从磁盘（或内核缓冲区）传输到网卡，而不需要经过应用程序的内存,&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&#34;35-总结&#34;&gt;3.5. 总结&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;生产者（Producer）发消息 -&amp;gt; Broker 收到后，找到 &lt;code&gt;TopicA&lt;/code&gt; 的分区 &lt;code&gt;Partition0&lt;/code&gt; -&amp;gt; 将消息追加写入到对应的 &lt;code&gt;.log&lt;/code&gt; 文件（假设是 &lt;code&gt;/var/lib/kafka-logs/TopicA-0/00000000000000000000.log&lt;/code&gt;）&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;消费者（Consumer）读消息 -&amp;gt; 只要知道该消息所在的分区和 offset，就可以去读取对应分区的日志文件中该 offset 的位置（当然中间是由 Kafka 协调完成的）, 读完后并不影响 Kafka 对消息的保留&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Kafka 以 segment 为单位做分段 -&amp;gt; 当文件大小或时间到了，就滚动新文件&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;日志清理 -&amp;gt; 当最早的一些 segment 的消息都过了保留时间（或超了预设总大小），则 Kafka 定时删除这些 segment 文件，消息也随之被物理删除&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;结果 -&amp;gt; 消费与删除解耦，Consumer 消费并不决定是否删除数据；真正的删除取决于保留策略和 Log 目录的定期清理&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;4-消费者负载均衡&#34;&gt;4. 消费者负载均衡&lt;/h2&gt;
&lt;p&gt;消费者负载均衡是指在消息队列系统中，当有多个消费者需要处理消息时，系统会自动将工作（消息）合理分配给这些消费者，确保每个消费者都能分担一部分任务，而不是让某个消费者超载或闲置。简单来说，就是“大家一起干活，分工要公平”, 在 Kafka 中，这种负载均衡是通过 Consumer Group 和 Partition 来实现的,&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Consumer Group&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;每个消费者都隶属于一个“消费者组”（比如 &lt;code&gt;group.id=test_group&lt;/code&gt;）&lt;/li&gt;
&lt;li&gt;在同一时间, 一个分区只能被消费者组中的一个消费者实例消费, 因为一个分区只会被一个消费者处理, 所以同一个消息不会被多个消费者重复消费, 保证了消息处理的唯一性&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;分区分配&lt;/strong&gt;：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;假设有个 Topic 有 4 个分区（P0, P1, P2, P3），消费者组里有 2 个消费者（C1, C2）&lt;/li&gt;
&lt;li&gt;Kafka 会自动分配：比如 C1 处理 P0 和 P1，C2 处理 P2 和 P3&lt;/li&gt;
&lt;li&gt;这种分配是动态的，由 Kafka 的 Coordinator，一个 Broker 来决定&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;并行处理&lt;/strong&gt;：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;C1 和 C2 各自从自己的分区读取消息并处理，互不干扰，这样可以同时处理更多消息，提高效率&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;再平衡（Rebalance）&lt;/strong&gt;：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;如果 C2 宕机了，Kafka 检测到消费者数量变化，会重新分配任务，让 C1 接管所有 4 个分区&lt;/li&gt;
&lt;li&gt;如果新增一个消费者 C3，Kafka 也会重新分配，比如：C1 处理 P0，C2 处理 P1，C3 处理 P2 和 P3&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;消费者组通过分工, 让每个消费者处理一部分分区, 实现并行消费, 同时, Kafka 保证每个分区只分配给一个消费者, 避免重复处理&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;消费者比分区多怎么办？&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;如果消费者数量超过分区数, 多余的消费者会闲置&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Kafka 消费者组是如何实现负载均衡的?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;说明消费者组通过 Coordinator（Kafka Broker 中的一个角色）管理分区分配, 当消费者加入或退出时触发再平衡, 再平衡时，所有消费者会暂停处理消息, 等分配完成再继续, 如果频繁发生, 可能会影响性能&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;如果消费者处理能力跟不上生产者怎么办？&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;可以增加消费者实例（提高并行度）, 优化消费者处理逻辑, 或者调整分区数（更多分区支持更多并发）, 还可以提到背压（Backpressure）问题, 必要时限流生产者&lt;/p&gt;
</content>
    </item>
    
  </channel>
</rss>
