---
title: Nginx 架构和事件驱动
date: 2025-05-01 17:02:38
categories:
 - 面试
tags:
 - 面试
 - 分布式面试
---

## 1. 从一个 HTML 文件开始

你是个程序员，有一天你在电脑上写了一段文字，保存为一个 `.txt` 文件。你打开它，只能看到黑白的纯文本。太单调了！如果我们能让这段文字变成一个网页，像浏览器里那种五颜六色、能点击、能跳转的页面，就有趣多了。

怎么办？我们来给文字加点“魔法”。比如你在文字前加上 `<h1>` 标签，浏览器一看就知道：“噢，这是标题！”再加上 `<ul>` 和 `<li>` 标签，就能变成列表。甚至用 `<img>` 加个网址，还能自动显示图片。

这些加了尖括号的“魔法字符”就叫 HTML 标签。文件加上这些标签，浏览器识别后能渲染出漂亮的页面。为了区分这些文件和纯文本，我们给它换个后缀名叫 `.html`。

你现在能在自己电脑上用浏览器打开这个 HTML 页面。但问题来了——我们平时访问的网站是从远方服务器上加载的，那浏览器是怎么拿到这些文件的呢？

答案是：靠 Nginx！

## 2. 什么是 HTTP 服务器？

设想我们有个远程服务器, 里面放了 HTML 文件, 我们希望让浏览器可以通过一个网址拿到这个文件, 解决办法其实很简单:

我们在远程服务器上启动一个程序, 让它监听用户的请求, 你在浏览器输入网址, 按回车, 这个程序就接收到请求, 然后把 HTML 文件发送回来, 浏览器就能显示页面了

这个专门响应 HTTP 请求、返回网页内容的程序, 我们就叫它 **HTTP 服务器**, Nginx 最开始, 就是这么个程序

> **URL 的概念**
>
> 不难发现 URL 就像个路径 xxx.com 是根目录, 路径一般都是名词, 这是因为我们认为 URL 是用来定位资源的, 而一个资源应该是一个名词,  比如 `https://cloud.tencent.com/developer/article/1626239`: developer, article, id 用来定位唯一文章的内容

> 所以我们在设计 REST API 的时候尽量用名词标识每个路径, 而不是动词, 然后全部使用小写, 可以使用 `-` 连接单词

## 3. 反向代理是干什么的？

上面说的都是静态的 HTML 页面, 假设你做了一个电商网站, 除了展示页面, 还有一个后端服务以便 HTML 页面可以显示动态的数据, 提供商品数据, 

一般的加载流程是前端静态页面加载好后, 会向后端服务器发请求, 拿到商品信息再显示出来, 一开始请求量不大, 一个后端服务足够用, 但如果访问量越来越高, 后端撑不住了, 就得多部署几个服务实例, 可问题是: 浏览器怎么知道该请求哪一个服务？

这时候我们就引入一个“中间人”——**反向代理服务器**, 它只对外暴露一个统一的网址, 收到请求后, 根据策略（比如随机、轮询、按权重）把请求分发给后端的多个服务, 实现**负载均衡**, 

举个例子：你打电话叫外卖, 你不需要知道是哪个骑手送的, 只管拨一个统一号码, 系统会安排骑手接单, 反向代理就像这个统一的调度系统, Nginx 很擅长干这个活, 它能接住前端请求, 再分发到正确的后端服务

## 4. 网关能做的更多：模块化能力

既然 Nginx 这个“中间人”掌握了所有流量的进出，那我们可以顺便让它多做点事:

- **记录日志**：谁访问了什么，成功还是失败，这些都能帮你排查问题
- **压缩内容**：数据传输前压缩一下，节省流量，提速加载
- **限流或封禁**：发现某 IP 请求太频繁？直接拦住
- **修改请求或响应**：可以在请求到后端前悄悄“改词”，比如增加身份验证

Nginx 把这些功能做成“插件”或“模块”，你可以按需开启，非常灵活。更厉害的是，它不止支持 HTTP，还能通过模块支持 TCP、UDP、HTTP/2、WebSocket 等协议, 简直是个万能流量管家

> **各协议支持说明**
>
> - **TCP（传输控制协议）** 用于如 MySQL、Redis 等需要可靠连接的服务, Nginx 可以充当 TCP 负载均衡器, 分发数据库请求
> - **UDP（用户数据报协议）** 用于如 DNS、视频流等应用, Nginx 可以处理 UDP 请求流量, 并进行转发或限流
> - **HTTP/2（新一代 HTTP 协议）** 相比 HTTP/1.1, 支持多路复用、头部压缩、并发等, 开启模块后, Nginx 可以支持浏览器与服务端之间使用 HTTP/2 提高性能
> - **WebSocket（实时通信协议）** 用于浏览器与服务端之间建立长连接, 进行实时通信（如聊天室、实时通知等）, Nginx 本来就作为流量入口, 已经接收所有请求, 通过 Nginx 做 WebSocket 转发, 可以让客户端只连接一个地址（统一入口）, 后端服务可以灵活部署、更新、重启而不中断连接

## 5. 配置文件：告诉 Nginx 要干什么

Nginx 有一个核心配置文件：`nginx.conf`。就像菜谱，你告诉它要干哪些活，它就按你的指令执行：

```nginx
server {
    listen 80;
    location / {
        proxy_pass http://backend;
    }
}
```

这段配置意思是：监听 80 端口, 收到请求后转发到名叫 `backend` 的后端服务去, 只要你配置得当, 它啥都能帮你做

## 6. 单线程：简单高效的处理方式

很多人以为服务器程序一定是多线程的，但 Nginx 最初设计是**单线程模型**：所有请求进来后，统一在一个线程里排队、处理，不开多个线程，不用担心线程安全和锁的问题，效率反而很高。

有点像快餐店的点单窗口：所有顾客排成一列，前一个点完，后一个再来，虽然一个窗口慢点，但流程清晰、省事还高效。

## 6. 多 worker：多进程并行处理

那单线程是不是性能瓶颈？是的。所以 Nginx 用了多进程的办法——它会启动多个 **worker 进程**，每个都运行一个单线程，各自独立，互不干扰。

一旦请求到来，系统会把它分配给某个 worker，这样就能并行处理多个请求了。进程数通常设置为和 CPU 核心数一样，每个核心忙一个 worker，吃干榨净！

有同学可能会问：多个进程监听同一个端口不会冲突吗？其实操作系统早就支持这个功能了，比如 Linux 下的 `SO_REUSEPORT` 就可以让多个进程共享监听同一个端口。

## 7. 多进程协作：共享内存的作用

多个 worker 虽然独立，但有时候也要共享数据。比如你想限制一个 IP 每秒最多访问 10 次，但请求会被不同 worker 处理，如果每个 worker 自己记录访问次数，那就乱套了。

这时候就用到了 **共享内存**。多个进程可以共同读写一块内存，像开了个共享文档，大家都能看到同一份数据，便于统一判断和操作。

## 8. 缓存：proxy cache

前端请求数据时，Nginx 会帮忙转发到后端。如果每次都去后端拿数据，太浪费资源。我们可以让 Nginx 把后端的响应“顺便”存一下，下次有人再请求同样的内容，直接从缓存中拿，速度更快、压力更小。

这个缓存通常存磁盘上而不是内存里，毕竟磁盘便宜、内存贵。这就叫 **proxy cache**，它是 Nginx 非常实用的加速手段。

举个例子：你去食堂点饭，窗口刚炒好一锅宫保鸡丁。第一个人吃走了，后面几个人还想点一样的，这时候窗口就直接从锅里舀，不用每次再炒一遍。

## 9. master 进程：调度大脑

现在我们有多个 worker，它们都在干活，但怎么启动、关闭、重启它们呢？Nginx 引入了一个新的进程：**master 进程**。

master 是管理者，专门负责：

- 读取配置文件
- 启动或关闭 worker
- 升级时一个一个重启 worker，避免服务中断（也叫“滚动升级”）

就像一个车队经理，指挥每个司机什么时候发车、什么时候休息，保证服务不断线

## 10. Nginx 是什么？

所以综合来看，Nginx 是一个超强的网络中间件，它：

- 是一个高性能 HTTP 服务器
- 是一个强大的反向代理
- 是一个可配置、可扩展的网关
- 是一个支持多协议、多进程、高并发的服务平台

它可以处理网页访问，也可以转发接口请求，还能压缩数据、限制流量、缓存响应，是互联网世界不可缺少的“隐形英雄”。

而且，它性能强悍，每秒轻松处理五万个请求，部署你的“小项目”那是轻轻松松！

了解更多: https://mp.weixin.qq.com/s/-XXOasEBBH3p00OJkx4lzw

## 11. 为何 Nginx 高并发?

Nginx 采用**事件驱动**的架构来处理客户端请求, 而事件驱动的核心是**事件循环**, 事件循环在监听套接字的时候会用到 **IO 复用技术**, 因为 套接字就是文件呀, 一切皆文件嘛

> 事件驱动的核心是**事件循环**, 无论是 Node.js 的事件驱动机制利用的是 libuv 的事件循环, Nginx 的事件驱动机制当然也有它自己的事件循环实现

### 11.1. 非阻塞IO + 多路复用

在讨论 IO 模型的那篇文章中, 提到过非阻塞 IO 的实现需要轮训, 而轮训非常占用资源, 因此 非阻塞 IO 经常配合 多路复用来使用, 一般非阻塞 IO + 多路复用 都是偏底层的东西, 毕竟 多路复用 像 epoll kqueue 都是通过直接监听套接字 socket 来实现的, 我们编程种遇到的 异步编程 `awsit/async`, `promise` 都是更高一层的概念, 支持异步编程的框架比如 Node.js 和 FastAPI 底层就是利用 非阻塞 IO 和 多路复用来实现的, 通过图表更容易比较:

| 层级                 | 示例                      | 说明                      |
| -------------------- | ------------------------- | ------------------------- |
| **高级语言异步语法** | `async/await`、Promise    | 开发者使用的编程接口      |
| **异步框架**         | Node.js、FastAPI、aiohttp | 提供 event loop、任务调度 |
| **事件循环**         | libuv、asyncio、uvloop    | 负责调度任务和 I/O 事件   |
| **底层 I/O 模型**    | 非阻塞 I/O + epoll/kqueue | 操作系统级别的能力        |

### 11.2. Nginx 的事件循环

介绍事件驱动的那篇文章里提到了 Node.js libuv 事件循环的实现机制, 这次来看看 Nginx 的事件循环机制, 

每次说到事件驱动, 就离不开另外三个概念: 事件循环 非阻塞 IO 多路复用, 三者从下到上可视为:

1. **非阻塞 I/O ⇒** 解决「单个 fd 调用」不阻塞

2. **多路复用 ⇒** 解决「多个 fd 事件聚合就绪通知」
3. **事件循环 ⇒** 解决「持续取事件→派发处理→回到等待」的流程控制

### 11.3. Nginx 的事件循环

**关键组件**

| 组件                          | 职责                                 | 与谁直接协作        |
| ----------------------------- | ------------------------------------ | ------------------- |
| Master 进程                   | 加载配置、生成/回收 Worker、热重启   | OS、Workers         |
| Worker 进程                   | 真正处理所有网络连接与请求           | Master、事件循环    |
| 事件循环                      | 取就绪事件 → 调用处理函数 → 回头再取 | 多路复用、定时器    |
| 多路复用                      | 一次返回“哪些 fd 已就绪”             | 非阻塞 fd、事件循环 |
| 非阻塞 I/O                    | 保证读写立即返回、不悬挂进程         | 内核 socket、文件   |
| 定时器                        | 统一管理超时与延迟任务               | 事件循环            |
| 模块流水线 (Handler / Filter) | 根据业务配置完成请求处理             | 事件循环、缓冲区    |

**逻辑结构树**

```
Master
└─ Worker[N]
    ├─ Event Loop
    │   ├─ Multiplexer (epoll)
    │   └─ Timer Manager
    ├─ Non-blocking Connection Pool
    └─ Module Pipeline
        ├─ Handlers  (static, proxy, fastcgi…)
        └─ Filters   (gzip, chunked…)
```

**运行示例：访问静态文件**

- Master 把监听端口交给 4 个 Worker（假设 4 核）后就休眠等待信号

- 某 Worker 进入 **事件循环**
  - (a) 计算最近定时器 → (b) 调用 **epoll_wait**

- 客户端 TCP 建链成功：

  - epoll 把监听 socket 的“可读”事件返回

  - Worker 从 **事件循环**中取出事件，⁠accept 新连接 → 设为 **非阻塞** → 放入连接池

- 读取 HTTP 请求：
  - epoll 再次返回“客户端 fd 可读”
  - Worker ⁠recv 数据；因非阻塞，若数据不足立即返回 EAGAIN
  - 收到完整请求行后，推入 **模块流水线**，由 *static handler* 判定是静态文件

- 发送文件：
  - static handler 调用 ⁠sendfile 把文件描述符直接交给内核
  - 依旧受 epoll 监管：socket 可写再继续发，不会阻塞 Worker

- 连接空闲进入 **定时器** 监管：
  - 若客户端长时间无数据，定时器触发关闭连接，释放资源

整个过程中：

- **非阻塞 I/O** 确保任何一次 ⁠recv/send 都不会把 Worker 卡住

- **多路复用**（epoll）把“哪些 fd 就绪”一次性告诉 Worker，避免频繁轮询

- **事件循环** 把“等待 → 分发 → 处理 → 再等待”串成闭环

- **模块流水线** 在得到数据后决定如何处理（这里是静态文件）

- **定时器** 负责踢掉长时间无响应的连接，防止资源泄露

这样, 一个 Worker 线程即可并发服务成千上万连接, 而 Master 进程则专注管理 Worker 和平滑重载

