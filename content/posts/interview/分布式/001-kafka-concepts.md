---
title: Kafka 消息队列
date: 2025-02-22 16:10:27
categories:
 - 面试
tags:
 - 面试
 - 消息队列面试
 - 分布式面试
---

## 1. 几个重要概念

Kafka 几个常见概念: Producer, Consumer, Broker, Topic, Partition:

- 在 Kafka 中, 集群里的每一台服务器都被称为 **Broker**, 负责接收生产者发送的消息并存储这些消息

- Topic 是 Kafka 中消息的逻辑分组, 生产者按照消息所属 Topic 将消息发送到 Broker, 消费者从  Broker 中读取消息
- 每个 Topic 可以分成多个分区, 然后不同的分区可能会存储在不同的 Broker 上, 例如: `user-clicks` Topic 有 3 个分区, 可能的存储是 Broker 1 存分区 0 和 1，Broker 2 存分区 2

> 注意 Broker 本身并不主动 “分发” 消息, 只负责存储消息并等待消费者主动拉取

分区（Partition）

- 每个 Topic 被分成多个分区, 分区是 Kafka 数据的基本存储单位
- 例如, 一个 Topic user-clicks 有 3 个分区: Partition 0、Partition 1、Partition 2

副本（Replica）

- 每个分区可以有多个副本（由复制因子 replication-factor 决定），这些副本分布在不同的 Broker 上

- 例如，replication-factor=2 表示每个分区有 2 个副本：一个主副本（Leader Replica）和一个从副本（Follower Replica）

> 在 Kafka 集群里, 不是一台 Broker 扛所有活, 而是多台 Broker 一起上, 数据先按照 Topic 分类, 每个 Topic 又被拆分成多个分区, 这些分区会均匀分布到不同的 Broker 上, 这样生产者在写入数据、消费者在读取数据时相关请求会自动分散到各个 Broker, 从而实现负载均衡和高吞吐量

## 2. 生产者发送消息之前做了什么

如果仔细想一下, 一个 Topic 的分区有很多嘛, 散布在不同的 Broker 上, 不仅会疑问 ,生产者生产的消息存储在哪个 Broker 的哪个 Topic 分区? 另外消费者消费消息, 怎么保证消息的顺序? 因为消息会被散布到不同 Broker 的 Topic 的不同分区上, 这其中肯定有一个逻辑, 而不是随机的, 不然岂不是乱套了?

### 2.1. 发送前要确定的事

当生产者发送一条消息时，需要确定两件事:

1. 消息最终存储在哪个 Topic 的哪个 Partition？
2. 这条消息应该发送给集群中的哪个 Broker？

### 2.2. 首先确定 Topic 和 Partition

生产者在发送消息时**必须**指定目标 `Topic`, 这是消息分类的基本单元, 一旦确定了 Topic, 接下来就要决定这条消息进入该 Topic 下的哪个 `Partition`, 这由**分区器 (Partitioner)** 决定, 主要有以下几种策略:

- 生产者可以在发送消息时直接指定一个 Partition ID, 这种情况下, 消息就直接发送到指定的 Partition, 这用得相对较少
- 生产者可以为消息指定一个 `Key` (例如，用户 ID、订单 ID 等), Kafka 的默认分区器会根据这个 Key 计算一个哈希值, 然后用这个哈希值对 Topic 的总分区数取模 (`hash(key) % num_partitions`), 得到的结果就是目标 Partition ID
  - 使用相同的 Key 发送的消息**保证**会被发送到同一个 Partition, 这对于需要保证相关消息处理顺序的场景非常重要（因为单个 Partition 内的消息是有序的）
- 如果生产者没有指定 Key, 那么默认的分区策略通常是轮询 (Round-Robin)

### 2.3. 最后确定目标 Broker

- 在 Kafka 集群中，每个分区（Partition）就像一个“任务小组”, 负责存储某个 Topic 的一部分数据, 这个小组有一个“组长”（Leader 副本）和可能有几个“组员”（Follower 副本）, 所有的数据读写操作（比如发送消息或读取消息）都必须找“组长”来处理, “组员”只负责跟着“组长”同步数据, 不能直接处理读写请求
- 生产者首先需要知道目标 Partition (由步骤 1 确定) 的 Leader 副本位于哪个 Broker 上
- 生产者会向集群中的任意一个 Broker (通常是配置的 `bootstrap.servers` 中的一个) 发送元数据请求 (Metadata Request), 获取整个集群的元数据信息, 这些信息包括：哪些 Topic 存在、每个 Topic 有哪些 Partition、每个 Partition 的 Leader 副本在哪个 Broker 上等
- 一旦生产者知道了目标 Partition 的 Leader Broker，它就会**直接**将消息发送给那个 Leader Broker
- 如果 Leader Broker 发生故障，Kafka 控制器 (Controller) 会从 Follower 副本中选举出新的 Leader, 生产者会更新其元数据缓存，然后将后续消息发送给新的 Leader Broker

## 3. 消费者如何消费消息 保证顺序

Kafka 的消息并不是“只能被消费一次”, Kafka 允许同一个消息被**多个消费者组**独立消费, 因为每个消费者组维护自己的**偏移量（Offset）**, 独立跟踪自己消费了哪些消息, 这就像同一本书可以被不同的人借阅, 每个人记录自己读到哪页, 互不干扰

要理解消息不是消耗品, 而是持久化到硬盘中的数据, 不是那种被消费了就没有了, 一个消息可以被多个消费者读取, 但是如果消费者的逻辑是一样的, 比如都是从消息队列中取出消息, 然后实现发送邮件通知功能, 那一个消息就没有必要被多个具有相同逻辑的消费者读取, 只读取一次就行了, 怎么实现呢?

Kafka 的核心机制之一是: 在一个消费者组内, 一个 Partition 最多只能被组内的一个消费者实例消费, 可能不好理解, 解释一下: 

Topic 的某个分区可以被多个消费者消费是吧, 可是分区有个限制, 可以有多个消费者来读取我的信息, 但是一个消费者组只能派一个消费者进来, 然后每个消费者都会记住自己在该分区的当前偏移量, 一次拿一批数据, 分区为什么不直接只允许一个消费者读取呢?

因为一个可能的场景是不同消费者组需要订阅同一个 Topic, 比如一个组（group.id=order-processors）处理订单, 生成发货单, 另一个组（group.id=analytics）分析订单数据, 统计销售额, 这个是时候就有两个消费者(来自不同的组)来读取同一个分区的消息, 然后每个消费者都会记住自己在该分区的当前偏移量, 一次拿一批数据

当一个消费者组内的消费者订阅了 Topic 后, Kafka 会自动将这些 Topic 的所有 Partition **分配**给该组内的所有活跃消费者实例, 这个分配过程由组协调器 (Group Coordinator，一个 Broker 担任) 负责，目标是尽可能均匀地将 Partition 分配给组内的消费者, 如果一个 Topic 有 6 个 Partition, 而消费者组里有 3 个消费者实例, 那么理想情况下, 每个消费者会被分配到 2 个 Partition, 如果只有 1 个消费者, 它会被分配到所有 6 个 Partition

一旦消费者被分配了若干个 Partition, 它就知道自己需要负责消费哪些 Partition 了, 消费者会主动连接到其被分配的每个 Partition 的 **Leader Broker**, 然后消费者从 Leader Broker **拉取 (Pull)** 属于自己负责的 Partition 的消息

消费者会维护自己消费到每个 Partition 的 **偏移量 (Offset)**, 即它在每个 Partition 中读取到的最后一条消息的位置, 这个 Offset 会定期提交给 Kafka (存储在 Broker 的一个内部 Topic `__consumer_offsets` 中)，以便在消费者重启或发生故障切换时，能够从上次停止的地方继续消费

- 与上面的相呼应 每个 消费者都会维护一个自己的偏移量, 一个分区的消息可以被多个消费者消费, 但这些不可以来自同一个消费组, 也就是说我可以让多个消费者过来拿消息, 但一个消费者组只可以派来一个人来拿
- 另外 消息 不是那种消费了就没有了, 不是消耗品, 而是持久化到硬盘中的数据, 每个消费者都会记住自己在该分区的当前偏移量, 一次拿一批数据

## 4. 异步处理

异步处理是指任务的发起和执行不要求实时同步完成, 消息队列常用于异步处理, 生产者将消息发送到队列后无需等待消费者立即处理, 可以继续执行其他任务, 从而提高系统效率, 

之前讨论高并发点赞的问题, 用到了 Redis Lua 脚本保证了 `检查+更新` 面临的数据一致性问题, 然后利用 Kafka 实现了异步更新到数据库, 这也算是消息队列异步处理常见的一个应用场景, 

> 异步处理优点是解耦服务、提高响应速度和容错性；缺点可能是数据一致性难以保证（比如消费者处理失败），需要额外的错误处理机制（如重试或死信队列）

## 5. 消息持久化

我觉得至少有几个问题需要先弄明白, 我们知道消息由生产者产生发送到 Broker, 然后 Broker 存储消息, 之后的事由 消费者主动消费(拉取)消息, 

- 消息默认存在哪个位置的?  

- 为什么需要消息持久化呢, 消息不就是为了消费的吗, 如果存在磁盘保存起来, 消费者频繁读取, 读取之后的消息应该视为无用的垃圾了吧, 难道还要分别删除, 这也太浪费性能了吧?

### 5.1. 消息默认存在哪个位置的?  

在 Kafka 中, 消息是按 Topic 归类的, 可以理解为一类消息放在同一个 Topic 中:

- 每个 Topic 的每个分区对应一个日志文件（例如 topic-name-0.log）

- 如果一个 Topic 只有 1 个分区，那么所有消息都会顺序追加到这个分区上
- 如果一个 Topic 有多个分区，那么生产者会根据一定的策略（Key 的哈希或者轮询等）把消息分散到不同的分区

在 Kafka 的 Broker 上, 每个分区的底层都对应着一个日志文件, 这个日志并不是单独的一个物理文件，而是一系列 Segment 文件的有序集合, 形成一个“日志”概念:

- 你可以把它理解成一个“顺序追加写”的结构, 每当生产者发送的消息抵达该分区时, Kafka 就将它顺序地追加到 Log 的尾部（对应 Segment 文件）
- 为了方便维护和查询，Kafka 会把一个分区的 Log 拆分为多个 Segment 进行管理

### 5.2. 为什么是磁盘而不是内存？

简单一句话为了保证可靠性, 消息队列和 Redis 缓存还不一样, 缓存的数据丢失可以在业务逻辑上通过双写一致性保证, 毕竟缓存的数据就是为了提高速度, 权威数据 Source of Truth 还是在数据库里的, 而消息队列不同, 消息丢了就是丢了, 因为它本身就是权威数据, 

在消息被消费者消费之前, 如果 Broker 宕机, 内存中的消息会丢失, 而磁盘上的消息可以恢复, 

- Kafka 的设计目标是高吞吐量和高可靠性，直接把消息存在内存中虽然快，但内存容量有限，且宕机后数据会丢失
- Kafka 通过顺序写入磁盘（而不是随机读写）和操作系统的页面缓存（Page Cache），让磁盘的性能接近内存的读写速度

> 现代磁盘（无论是机械硬盘还是 SSD）在处理顺序写入时, 性能表现通常远优于随机写入:
>
> - 当数据是顺序写入的时候, 磁盘连续地写入数据, 不需要频繁地更换写入位置, 避免了磁头寻道（或者在SSD中内部块寻址）的开销, 从而极大地提高了写入速度, 而随机写入要求磁盘在不同位置之间不断切换, 造成额外的延时和性能下降, 
> - Kafka 采用的是**追加写入**的方式, 也就是每次都是在日志文件的末尾顺序写入数据, 从而避免了随机访问的开销

看完上面的不仅好奇 Kafka 还能控制操作系统的页面缓存吗? 这是怎么实现的?

#### 5.2.1. 什么是页面缓存 (Page Cache)

页面缓存是操作系统在内存中开辟出的一块区域, 用来临时存储从磁盘读取的数据, 或者即将写入磁盘的数据, 其主要作用有：

- 读缓存: 当应用再次请求已经被缓存的数据时，可以直接从内存中获取数据，大大提高读取速度

- 写缓存: 数据写入时，操作系统可以先将数据写入页面缓存，然后异步地将数据刷新（flush）到磁盘，这样应用看起来是直接在内存中写入数据

#### 5.2.2. Kafka 怎么利用页面缓存

Kafka 是一个分布式消息系统，它需要处理大量的消息读写。为了做到高吞吐量和高可靠性，Kafka 选择把消息持久化到磁盘上，而不是只保存在内存中。但磁盘很慢，怎么才能让性能接近内存呢？答案就是巧妙利用操作系统的页面缓存。

**顺序写入磁盘**

- Kafka 写入数据时，不是随机跳来跳去地写（随机写很慢），而是按顺序追加到日志文件末尾
- 顺序写入非常快，因为磁盘读写时不需要频繁移动磁头（对于机械硬盘）或者做复杂寻址（对于 SSD）
- 写完之后，这些数据会被操作系统自动加载到页面缓存中
- 顺序追加写入可以利用操作系统对顺序数据写入的优化, 这让操作系统更容易把数据缓存到页面缓存中

> 操作系统在管理页面缓存时, 更倾向于**缓存连续的数据块**, 顺序写入的数据通常会被预先加载到页面缓存中, 因为操作系统认为接下来很可能还会访问相邻的数据, 这样可以避免频繁地进行磁盘读写, 直接从内存中读取数据, 速度更快

**依赖页面缓存加速读取**

- 当消费者（Consumer）来读取消息时，Kafka 不会直接去磁盘找数据，而是让操作系统从页面缓存里拿
- 因为刚写入的数据还在页面缓存中（内存里），读取速度几乎和直接从内存读一样快
- 如果数据不在缓存中，操作系统会从磁盘加载到页面缓存，然后再给 Kafka，这样后续的读取也能变快

**尽量少干预缓存管理**

Kafka 并不自己管理内存, 而是把缓存的工作交给操作系统, 操作系统的页面缓存机制已经很成熟, 能根据系统的内存使用情况自动调整哪些数据保留在缓存里, 哪些可以丢弃

### 5.3. 消息被消费后 会被立马删除吗

Kafka 不会在每条消息写完后就跑去删除，而是 “以 Segment 为单位” 进行清理：

1. 当 Segment 中所有消息都超过了保留时间（或者日志大小达到限制）时, 这个 Segment 文件就可以被删除
2. Kafka 会周期性地检查每个分区日志中最早的 Segment 是否已经满足删除条件, 如果满足, 就把这个 Segment 文件（以及对应的 `.index`、`.timeindex` 文件）从磁盘上删除

Consumer 读取消息的时候，只需要记录自己当前消费到哪个 offset 并提交, 即使这条消息还在 Kafka 的日志文件里, 它是否被删除是由上面提到的保留策略决定, 并不因为 Consumer 读到它就删除

### 5.4. 为什么不浪费性能

- **顺序写Append-only + 批量处理 Batch **：消费者不是一条条读，而是批量拉取消息（比如一次拉 1000 条），减少频繁交互, 最大化磁盘吞吐，减少网络请求、磁盘刷盘次数，提升写入与读取性能

- **零拷贝技术**：Kafka 使用操作系统的零拷贝（Zero Copy）机制，从磁盘到网络传输消息时不经过用户态，效率极高

- **操作系统 Page Cache**：通过操作系统缓存机制来提升文件的读写效率，减少实际磁盘 IO；配合零拷贝进一步提升传输性能
- **自动清理**：消息过期后，Kafka 后台线程自动删除老日志，不需要人工干预，也不需要消费者操心

> **什么是零拷贝（Zero Copy）？**
>
> 通常情况下，当程序（比如 Kafka 的 Broker）需要把数据从磁盘发送到网络（比如给消费者），会涉及多次数据拷贝：
>
> 1. 操作系统从磁盘读取数据，拷贝到内核态的缓冲区（Kernel Buffer）
> 2. 从内核态缓冲区拷贝到用户态的应用程序内存（比如 Kafka 的进程内存）
> 3. 应用程序处理完后，再把数据从用户态内存拷贝回内核态的网络缓冲区
> 4. 最后从内核态网络缓冲区发送到网卡，传给消费者
>
> 这个过程涉及多次数据拷贝（通常至少 4 次），而且在用户态和内核态之间切换（上下文切换），会消耗 CPU 和时间，效率不高, **零拷贝**的目标是：尽量减少这些拷贝步骤，尤其是用户态和内核态之间的来回拷贝。操作系统提供了一些技术（比如 `sendfile` 系统调用），让数据直接从磁盘（或内核缓冲区）传输到网卡，而不需要经过应用程序的内存, 

### 5.5. 总结

- 生产者（Producer）发消息 -> Broker 收到后，找到 `TopicA` 的分区 `Partition0` -> 将消息追加写入到对应的 `.log` 文件（假设是 `/var/lib/kafka-logs/TopicA-0/00000000000000000000.log`）

- 消费者（Consumer）读消息 -> 只要知道该消息所在的分区和 offset，就可以去读取对应分区的日志文件中该 offset 的位置（当然中间是由 Kafka 协调完成的）, 读完后并不影响 Kafka 对消息的保留

- Kafka 以 segment 为单位做分段 -> 当文件大小或时间到了，就滚动新文件

- 日志清理 -> 当最早的一些 segment 的消息都过了保留时间（或超了预设总大小），则 Kafka 定时删除这些 segment 文件，消息也随之被物理删除

- 结果 -> 消费与删除解耦，Consumer 消费并不决定是否删除数据；真正的删除取决于保留策略和 Log 目录的定期清理

## 6. 消费者负载均衡

消费者负载均衡是指在消息队列系统中，当有多个消费者需要处理消息时，系统会自动将工作（消息）合理分配给这些消费者，确保每个消费者都能分担一部分任务，而不是让某个消费者超载或闲置。简单来说，就是“大家一起干活，分工要公平”, 在 Kafka 中，这种负载均衡是通过 Consumer Group 和 Partition 来实现的, 

**Consumer Group**

- 每个消费者都隶属于一个“消费者组”（比如 `group.id=test_group`）
- 在同一时间, 一个分区只能被消费者组中的一个消费者实例消费, 因为一个分区只会被一个消费者处理, 所以同一个消息不会被多个消费者重复消费, 保证了消息处理的唯一性

**分区分配**：

- 假设有个 Topic 有 4 个分区（P0, P1, P2, P3），消费者组里有 2 个消费者（C1, C2）
- Kafka 会自动分配：比如 C1 处理 P0 和 P1，C2 处理 P2 和 P3
- 这种分配是动态的，由 Kafka 的 Coordinator，一个 Broker 来决定

**并行处理**：

- C1 和 C2 各自从自己的分区读取消息并处理，互不干扰，这样可以同时处理更多消息，提高效率

**再平衡（Rebalance）**：

- 如果 C2 宕机了，Kafka 检测到消费者数量变化，会重新分配任务，让 C1 接管所有 4 个分区
- 如果新增一个消费者 C3，Kafka 也会重新分配，比如：C1 处理 P0，C2 处理 P1，C3 处理 P2 和 P3

消费者组通过分工, 让每个消费者处理一部分分区, 实现并行消费, 同时, Kafka 保证每个分区只分配给一个消费者, 避免重复处理

**消费者比分区多怎么办？**

如果消费者数量超过分区数, 多余的消费者会闲置

**Kafka 消费者组是如何实现负载均衡的?**

说明消费者组通过 Coordinator（Kafka Broker 中的一个角色）管理分区分配, 当消费者加入或退出时触发再平衡, 再平衡时，所有消费者会暂停处理消息, 等分配完成再继续, 如果频繁发生, 可能会影响性能

**如果消费者处理能力跟不上生产者怎么办？**

可以增加消费者实例（提高并行度）, 优化消费者处理逻辑, 或者调整分区数（更多分区支持更多并发）, 还可以提到背压（Backpressure）问题, 必要时限流生产者

