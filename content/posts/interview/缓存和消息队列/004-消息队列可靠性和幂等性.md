---
title: 消息队列如何保证可靠性
date: 2025-04-15 19:56:20
categories:
 - 面试
tags:
 - 面试
 - 消息队列面试
---

## 1. 消息队列如何保证可靠性

### 1.1. 消息持久化

确保消息在系统崩溃或重启后不丢失

- 为提升性能, broker 可能先写入内存缓冲区, 再异步刷盘（需配置同步刷盘以确保强一致性）
- 异步刷盘可能在极短窗口内丢失消息（毫秒级），但吞吐量可提高 10 倍以上，业界常用

> 消息元数据（如 offset、时间戳）也需持久化，防止消费状态丢失
>
> 持久化存储通常结合定期清理（如按时间/大小删除）避免磁盘溢出

### 1.2. 副本机制（高可用，广泛使用）

**实现原理**：

- 单点故障（如节点宕机）会导致服务不可用或数据丢失，副本机制确保高可用和容错
- 消息在多个节点存储副本，主节点（leader）处理读写，从节点（follower）同步数据
- 主节点故障时，从节点选举为新主，自动接管服务

**业界实践**：

- Kafka 使用分区副本，RabbitMQ 使用镜像队列

- 副本数通常设为 2-3，兼顾可靠性和存储成本（副本过多增加开销）
- 同步 vs 异步复制
  - 同步复制（如 Kafka 的 acks=all）保证强一致性，但延迟稍高
  - 异步复制（如 Kafka 的 acks=1）性能更好，但可能丢少量消息，适用于对丢失敏感度低的场景

### 1.3. 消息确认机制（生产者与消费者，核心机制）

**生产者确认**

- 生产者发送消息后，等待 broker 确认（ack）
- 确认级别
  - 全程无需确认（火力全开，性能最高，可能丢消息）
  - 主节点确认（折衷，业界常用）
  - 多数副本确认（最可靠，延迟稍高）

**消费者确认**

- 消费者处理消息后，向 broker 发送确认（ack），broker 删除消息
- 未收到确认的消息可重新投递（at-least-once 语义）
- 自动确认（auto-ack）性能高，但可能丢失；手动确认（manual-ack）可靠，业界更常用

**业界实践**：

- Kafka：使用异步批量确认提高吞吐, 生产者配置 acks（0/1/all），消费者手动提交 offset
- RabbitMQ：生产者用 publisher confirm，消费者用 manual ack
- **优化**：异步批量确认（如 Kafka 缓冲发送）或延迟确认（如 RabbitMQ 批量 ack）提升吞吐。

> 重复消息可能因网络抖动或重试产生，需**幂等性**支持
>
> 确认超时需重试，增加系统复杂性，但不可或缺

## 2. 幂等性与去重

### 2.1. 三个语义

正确使用消息队列, 我们会考虑到消息防丢失、防重复, 3 个语义:

- At Least Once：一条消息最少被消费一次，但是可能会有重复消费
- Exactly Once：消息被精准消费一次，不丢失，也不会重复
- At Most Once：消息不会被重复消费，但是可能会有消息丢失

不同使用场景, 对语义的要求也不一样, 比如日志收集类的场景, At Most Once 就可以满足, 而支付类的场景则要求 Exactly Once

### 2.2. 导致重复消费的场景

消息重试或网络问题可能导致重复发送/消费, 幂等性防止重复处理影响业务逻辑:

- **生产者发送消息**到 Broker 后, 可能因为网络问题或服务器处理延迟, 没有收到确认响应, 生产者会认为消息发送失败并重新发送, 导致相同消息被发送多次
- **消费者消费消息后**, 返回 ACK 到 Broker 失败, 导致 Broker 没有修改偏移量, 同一条消息再次发送给消费者, 或者被消费者拉取到

### 2.3. 生产者防重

在没有幂等 Producer 之前, Kafka 生产者在发送消息后, 如果未能收到 Broker 的确认响应（ACK）, 会进行重试, 然而, 即使 Broker 成功接收并写入了消息, 但发送给生产者的 ACK 在途中丢失, 生产者会误认为消息发送失败而进行重试, 导致同一条消息被发送到 Kafka Topic 的同一个分区多次, 从而造成消息重复

Kafka 从 0.11.0 版本引入的幂等 Producer 是为了解决在消息发送过程中, 由于网络问题或 Broker 故障导致的**生产者重试引起消息重复问题**, Producer 通过为每条消息分配唯一标识并**在 Broker 端进行去重**, 从而**在生产者层面实现**了针对单个会话的“正好一次”（Exactly-Once）消息投递语义

- 当幂等性启用时, 每个生产者实例在启动后都会被分配一个唯一的 Producer ID (PID)
- 每条消息会附带一个单调递增的 Sequence Number, 与 PID 组合形成消息的唯一标识 PID + Sequence Number
- Broker 维护一个 `<PID, Topic, Partition>` 对应的序列号窗口, 记录最近接收的消息序列号
- 当收到消息时, Broker 检查该消息的 PID 和 Sequence Number 是否已在窗口中:
  - 如果序列号匹配预期（即连续递增）, 消息被接受并存储
  - 如果序列号重复（已存在），Broker 拒绝该消息，防止重复写入
  - 如果序列号超出预期范围（可能由于消息丢失或乱序），Broker 抛出异常，Producer 会重试
- 幂等 Producer 保证消息在单个分区内只被写入一次，即使 Producer 因网络问题重试发送也不会导致重复

> `<PID, Topic, Partition>` 是什么, 不应该是 PID + Sequence Number 吗?
>
> - `<PID, Topic, Partition>` 是一个 key, 这个键对应的值是一个**序列号窗口**, 记录了该 Producer 在该分区（Topic, Partition）中最近接收到的消息的 Sequence Number 范围
> - 窗口的作用是跟踪最近的 Sequence Number, 用于判断新到达的消息是否重复、是否按序、或是否超出了预期范围

**举例解释**

1. Producer P1 成功发送 Message 1 (Seq 1) 到 Partition A
2. Broker 成功接收 Message 1 (Seq 1), 并记录下 Producer P1 在 Partition A 的最新序列号为 1, 但在尝试发送 ACK 给 Producer P1 时, 网络发生瞬时故障, ACK 丢失
3. Producer P1 没有收到 Message 1 的 ACK, 根据重试策略, Producer P1 决定重试发送 Message 1
4. Producer P1 再次发送 Message 1 (Seq 1), 这次发送请求中包含了 Producer P1 的 PID 和序列号 1
5. Broker 收到 Producer P1 发来的消息, 检查其 PID (P1) 和序列号 (1), Broker 发现, Producer P1 在 Partition A 的最新已记录序列号已经是 1, 由于收到的消息序列号 (1) 不大于已记录的最新序列号 (1), Broker 判定这是一条重复消息, 直接丢弃, 不会再次写入 Partition A
6. Producer P1 最终可能会收到重试成功的 ACK（如果网络恢复）, 或者在达到最大重试次数后放弃, 但无论如何, Message 1 在 Partition A 中只会被成功写入一次

> 分区是什么意思 一个 topic 在同一个 broker 会有不同的分区吗, 还是一个 topic 有多个分区, 但只能在一个 broker 存在一个分区? 如果topic 在同一个 broker 会有不同的分区, 这又怎么记录消息的唯一性, 因为之前的是按照 `<PID, Topic, Partition>` 来记录窗口, 以及消费者如何按顺序消费同一个topic 下的不同信息呢? 是不是消费消息的顺序不重要?
>
> **问题一** 一个 Topic 在同一个 Broker 会有不同的分区吗？
>
> - 一个 Topic 完全可以在同一个 Broker 上拥有多个不同的分区
> - 例如一个 Topic "my-topic" 被配置为有 6 个分区 (P0, P1, P2, P3, P4, P5), 如果你的 Kafka 集群有 3 个 Broker (Broker A, Broker B, Broker C), 那么这些分区可能会被分配到这些 Broker 上: 
>   - Broker A 存储 P0, P3
>   - Broker B 存储 P1, P4
>   - Broker C 存储 P2, P5
>
> **问题二** 如果 Topic 在同一个 Broker 会有不同的分区, 这又怎么记录消息的唯一性？
>
> 消息的唯一性不是通过 Broker 来记录的, 而是通过 **Topic、分区号 (Partition ID) 和消息的偏移量 (Offset)** 的组合来确定的, 任何一条 Kafka 消息都可以通过 `(Topic 名称, 分区号, 偏移量)` 这个三元组来唯一标识
>
> **问题三** 消费者如何按顺序消费同一个 Topic 下的不同信息呢？
>
> Kafka **只保证单个分区内的消息顺序**, 消费者在消费时, 通常是拉取（Poll）分配给它的一个或多个分区的消息, 对于分配到的每个分区, 消费者会按偏移量的顺序逐条或批量读取
>
> **问题四** 是不是消费消息的顺序不重要？
>
> 这取决于你的应用场景, 如果你的应用处理的是独立事件, 事件之间的顺序没有强依赖关系（例如：网站点击事件、日志记录）, 那全局顺序就不重要
>
> 如果你的应用需要处理例如：创建订单 -> 更新订单状态 -> 完成支付, 那么全局顺序就很重要, 在这种情况下, 通常会使用该实体（如用户 ID 或订单 ID）作为消息的 **Key**, Kafka 保证具有相同 Key 的消息会被发送到同一个分区（默认使用 Key 的哈希值进行分区）, 这样消费者消费该分区时就能保证该 Key 相关的消息是按顺序处理的

> 我希望你可以解释一下 Kafka 中: 
>
> 当一个生产者发送一个消息到 broker, 这个消息的存储位置 比如 某个 topic 的某个 分区, 是什么确定的, 以及 什么决定的 一个消息被发送到哪个 broker, 是随机的吗?  另外, 消费者在消费消息的时候, 是不是需要指定 broker, 以及 topic, 以及 topic 对应的分区, 然后一直就在这里 pull 消息?
>
> -------
>
> **生产者发送消息 (Producer Side)**
>
> 当生产者发送一条消息时，需要确定两件事：
>
> 1. 消息最终存储在哪个 Topic 的哪个 Partition？
> 2. 这条消息应该发送给集群中的哪个 Broker？
>
> **首先确定 Topic 和 Partition**
>
> 生产者在发送消息时**必须**指定目标 `Topic`, 这是消息分类的基本单元, 一旦确定了 Topic, 接下来就要决定这条消息进入该 Topic 下的哪个 `Partition`, 这由**分区器 (Partitioner)** 决定, 主要有以下几种策略:
>
> - 生产者可以在发送消息时直接指定一个 Partition ID, 这种情况下, 消息就直接发送到指定的 Partition, 这用得相对较少
> - 生产者可以为消息指定一个 `Key` (例如，用户 ID、订单 ID 等), Kafka 的默认分区器会根据这个 Key 计算一个哈希值, 然后用这个哈希值对 Topic 的总分区数取模 (`hash(key) % num_partitions`), 得到的结果就是目标 Partition ID
>   - 使用相同的 Key 发送的消息**保证**会被发送到同一个 Partition, 这对于需要保证相关消息处理顺序的场景非常重要（因为单个 Partition 内的消息是有序的）
> - 如果生产者没有指定 Key, 那么默认的分区策略通常是轮询 (Round-Robin)
>
> **最后确定目标 Broker**
>
> - 在 Kafka 集群中，每个分区（Partition）就像一个“任务小组”, 负责存储某个 Topic 的一部分数据, 这个小组有一个“组长”（Leader 副本）和可能有几个“组员”（Follower 副本）, 所有的数据读写操作（比如发送消息或读取消息）都必须找“组长”来处理, “组员”只负责跟着“组长”同步数据, 不能直接处理读写请求
> - 生产者首先需要知道目标 Partition (由步骤 1 确定) 的 Leader 副本位于哪个 Broker 上
> - 生产者会向集群中的任意一个 Broker (通常是配置的 `bootstrap.servers` 中的一个) 发送元数据请求 (Metadata Request), 获取整个集群的元数据信息, 这些信息包括：哪些 Topic 存在、每个 Topic 有哪些 Partition、每个 Partition 的 Leader 副本在哪个 Broker 上等
> - 一旦生产者知道了目标 Partition 的 Leader Broker，它就会**直接**将消息发送给那个 Leader Broker
> - 如果 Leader Broker 发生故障，Kafka 控制器 (Controller) 会从 Follower 副本中选举出新的 Leader, 生产者会更新其元数据缓存，然后将后续消息发送给新的 Leader Broker
>
> ----
>
> **消费者消费消息 (Consumer Side)**
>
> - 消费者不直接指定要从哪个 Broker 或哪个具体的 Partition 拉取消息
> - 消费者通过 `subscribe()` 方法订阅一个或多个 Topic
> - **消费者必须属于一个 Consumer Group** （通过 `group.id` 配置指定）
>   - 常见的做法是 同一个 Topic 的所有消费者归为一个组
>   - 当然也有 不同组订阅同一个 Topic, 但每个组都收到该 Topic 的完整数据, 比如 一个组（group.id=order-processors）处理订单, 生成发货单, 另一个组（group.id=analytics）分析订单数据, 统计销售额
>   - Kafka 的消息并不是“只能被消费一次”, 相反，Kafka 允许同一个消息被**多个消费者组**独立消费, 因为每个消费者组维护自己的**偏移量（Offset）**, 独立跟踪自己消费了哪些消息, 这就像同一本书可以被不同的人借阅, 每个人记录自己读到哪页, 互不干扰
> - Kafka 的核心机制之一是: 在一个消费者组内, 一个 Partition 最多只能被组内的一个消费者实例消费
> - 当一个消费者组内的消费者订阅了 Topic 后, Kafka 会自动将这些 Topic 的所有 Partition **分配**给该组内的所有活跃消费者实例
> - 这个分配过程由组协调器 (Group Coordinator，一个 Broker 担任) 负责，目标是尽可能均匀地将 Partition 分配给组内的消费者
> - 如果一个 Topic 有 6 个 Partition, 而消费者组里有 3 个消费者实例, 那么理想情况下, 每个消费者会被分配到 2 个 Partition, 如果只有 1 个消费者, 它会被分配到所有 6 个 Partition
> - 一旦消费者被分配了若干个 Partition, 它就知道自己需要负责消费哪些 Partition 了
> - 消费者会主动连接到其被分配的每个 Partition 的 **Leader Broker**
> - 然后消费者从 Leader Broker **拉取 (Pull)** 属于自己负责的 Partition 的消息
> - 消费者会维护自己消费到每个 Partition 的 **偏移量 (Offset)**, 即它在每个 Partition 中读取到的最后一条消息的位置, 这个 Offset 会定期提交给 Kafka (存储在 Broker 的一个内部 Topic `__consumer_offsets` 中)，以便在消费者重启或发生故障切换时，能够从上次停止的地方继续消费
>   - 与上面的相呼应 每个 消费者都会维护一个自己的偏移量, 一个分区的消息可以被多个消费者消费, 但这些不可以来自同一个消费组, 也就是说我可以让多个消费者过来拿消息, 但一个消费者组只可以派来一个人来拿
>   - 另外 消息 不是那种消费了就没有了, 不是消耗品, 而是持久化到硬盘中的数据, 每个消费者都会记住自己在该分区的当前偏移量, 一次拿一批数据

### 2.4. 消费者防重 幂等性

幂等性是指一个操作执行一次和执行多次的结果是一样的, 下面是 **消费者** 实现代码:

```java
// 库存服务处理消息的代码示例
public void processInventoryReduction(InventoryMessage message) {
    String messageId = message.getMessageId(); // 消息唯一ID
    
    // 检查消息是否已处理
    if (messageProcessRepository.isProcessed(messageId)) {
        log.info("消息{}已处理，忽略重复消息", messageId);
        return;
    }
    
    try {
        // 执行库存扣减逻辑
        inventoryService.reduce(message.getProductId(), message.getQuantity());
        
        // 标记消息为已处理
        messageProcessRepository.markAsProcessed(messageId);
    } catch (Exception e) {
        log.error("处理消息{}失败", messageId, e);
        throw e;
    }
}
```

> 是不是好奇幂等性是怎么实现的? `messageProcessRepository` 是全局的仓库吗 也就是说 所有的客户端共享这一个仓库 确保消息被处理一次, 如果每个客户端单独维护一个仓库, 好像无法实现?
>
> 在多个消费者实例的情况下, `messageProcessRepository` 必须是全局共享的存储, 最常见的实现是一个数据库表, 记录已处理的消息ID, 而且不要忘了, 消费者也是运行在服务器上的, 而不是客户端

**幂等性实现的完整架构**

```sql
-- 消息处理记录表
CREATE TABLE message_process_record (
    message_id VARCHAR(50) PRIMARY KEY,  -- 消息唯一ID作为主键确保唯一性
    consumer_group VARCHAR(50) NOT NULL, -- 消费者组标识
    process_time TIMESTAMP NOT NULL,     -- 处理时间
    process_status VARCHAR(20) NOT NULL  -- 处理状态
);

-- 可选：添加索引优化查询
CREATE INDEX idx_consumer_message ON message_process_record(consumer_group, message_id);
```

**消费者实现**

```java
@Service
public class InventoryConsumer {
    
    @Autowired
    private JdbcTemplate jdbcTemplate;
    
    @Autowired
    private InventoryService inventoryService;
    
    // 消费者组标识，通常从配置中获取
    private static final String CONSUMER_GROUP = "inventory-service";
    
    @RabbitListener(queues = "inventory-queue")
    public void processInventoryReduction(InventoryMessage message) {
        String messageId = message.getMessageId();
        
        // 检查消息是否已处理 - 使用共享数据库
        if (isMessageProcessed(messageId)) {
            log.info("消息{}已处理，忽略重复消息", messageId);
            return;
        }
        
        try {
            // 尝试记录消息处理状态 - 使用数据库唯一约束确保幂等
            if (!markMessageProcessing(messageId)) {
                log.info("消息{}已被其他实例处理，忽略", messageId);
                return;
            }
            
            // 执行库存扣减逻辑
            inventoryService.reduce(message.getProductId(), message.getQuantity());
            
            // 标记消息为已成功处理
            markMessageProcessed(messageId);
        } catch (Exception e) {
            log.error("处理消息{}失败", messageId, e);
            // 可选：标记消息处理失败，以便后续分析
            markMessageFailed(messageId, e.getMessage());
            throw e;
        }
    }
    
    private boolean isMessageProcessed(String messageId) {
        int count = jdbcTemplate.queryForObject(
            "SELECT COUNT(*) FROM message_process_record WHERE message_id = ? AND consumer_group = ?",
            Integer.class, messageId, CONSUMER_GROUP);
        return count > 0;
    }
    
    private boolean markMessageProcessing(String messageId) {
        try {
            jdbcTemplate.update(
                "INSERT INTO message_process_record (message_id, consumer_group, process_time, process_status) " +
                "VALUES (?, ?, NOW(), 'PROCESSING')",
                messageId, CONSUMER_GROUP);
            return true;
        } catch (DuplicateKeyException e) {
            // 如果消息ID已存在，说明已被处理或正在处理
            return false;
        }
    }
    
    private void markMessageProcessed(String messageId) {
        jdbcTemplate.update(
            "UPDATE message_process_record SET process_status = 'PROCESSED', process_time = NOW() " +
            "WHERE message_id = ? AND consumer_group = ?",
            messageId, CONSUMER_GROUP);
    }
    
    private void markMessageFailed(String messageId, String errorMessage) {
        jdbcTemplate.update(
            "UPDATE message_process_record SET process_status = 'FAILED', error_message = ?, process_time = NOW() " +
            "WHERE message_id = ? AND consumer_group = ?",
            errorMessage, messageId, CONSUMER_GROUP);
    }
}
```

对于需要更强一致性保证的场景，可以结合分布式锁：

```java
@Autowired
private RedissonClient redissonClient;

public void processInventoryReduction(InventoryMessage message) {
    String messageId = message.getMessageId();
    String lockKey = "inventory_msg_lock:" + messageId;
    
    // 检查消息是否已处理
    if (isMessageProcessed(messageId)) {
        log.info("消息{}已处理，忽略重复消息", messageId);
        return;
    }
    
    // 获取分布式锁，确保同一时间只有一个实例处理该消息
    RLock lock = redissonClient.getLock(lockKey);
    try {
        // 尝试获取锁，等待2秒，持有锁10秒
        if (lock.tryLock(2, 10, TimeUnit.SECONDS)) {
            try {
                // 再次检查，防止锁等待期间其他实例已处理
                if (isMessageProcessed(messageId)) {
                    log.info("获取锁后再次检查：消息{}已处理", messageId);
                    return;
                }
                
                // 标记为处理中
                markMessageProcessing(messageId);
                
                // 执行业务逻辑
                inventoryService.reduce(message.getProductId(), message.getQuantity());
                
                // 标记为已处理
                markMessageProcessed(messageId);
            } finally {
                lock.unlock(); // 确保释放锁
            }
        } else {
            log.info("无法获取消息{}的处理锁，跳过处理", messageId);
        }
    } catch (InterruptedException e) {
        Thread.currentThread().interrupt();
        log.error("获取锁被中断", e);
    }
}
```

## 3. Redis List 简易消息队列可靠性分析

无论什么, 消息队列的可靠性都可以参考上面的规范, 这里我们主要讨论 redis 持久化, 所以上面的很多都没考虑, 保证消息的可靠性分为两个方面:

- 生产者使用消息持久化
- 消费者使用重试确认机制

### 3.1. 生产者 (Redis 持久化)

启用 Redis 的 AOF（Append-Only File）持久化，确保消息写入 List 后, 即使 Redis 重启也能恢复, AOF 的 `everysec` 模式适合大多数场景，若需更高可靠性可改为`always`:

```
appendonly yes
appendfsync everysec  # 每秒同步，平衡性能与可靠性
```

### 3.2. 消费者

**可靠取出**：使用 RPOPLPUSH（而非简单的 RPOP），将消息从主队列（如 email_queue）原子性地弹出并推入备份队列（如 backup_queue）, 处理成功后再从备份队列移除，确保消息不丢失

```pyyhon
def consume_task():
    try:
        order_id = redis_client.rpoplpush("email_queue", "backup_queue")
        if order_id:
            send_email(order_id)
            redis_client.lrem("backup_queue", 1, order_id)  # 确认处理成功
    except Exception as e:
        print(f"Error: {e}")
        # 任务仍在 backup_queue，可重试
```

**失败重试**：如果邮件发送失败（如网络问题），消费者可将任务重新推回主队列或记录到错误队列，稍后重试

```python
def retry_task(order_id):
    redis_client.lpush("email_queue", order_id)  # 重新推入主队列
```

> 使用 ⁠`RPOP` 时的主要问题是 一旦任务被弹出，它就从队列中消失了, 使用 RPOPLPUSH 的场景:
>
> ```
> 初始状态: 
> 待处理队列 = [任务1, 任务2, 任务3]
> 处理中队列 = []
> 
> 1. 应用程序执行 RPOPLPUSH → 将"任务3"从待处理队列移到处理中队列
>    待处理队列 = [任务1, 任务2]
>    处理中队列 = [任务3]
>    
> 2. 应用程序开始处理"任务3"
>    
> 3. 在处理过程中，应用程序崩溃
>    
> 结果: "任务3"仍然存在于处理中队列，可以在系统重启后恢复
> ```
>
> RPOPLPUSH 是一个原子操作，它确保元素从源列表移除并添加到目标列表的过程不会被中断